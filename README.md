# Generative_AI_with_LLM_Week2
Generative AI with Large Language Models course offered by Coursera in partnership with DeepLearning.AI

## Objective

This week we dive into fine-tuning large language models (LLMs) with instruction-based datasets can boost performance on specific tasks and possible risk of catastrophic forgetting of previous knowledge. Techniques like parameter-efficient fine-tuning (PEFT) minimize computational cost while mitigating forgetting, allowing LLMs to excel at diverse tasks through focused instruction-guided learning.

## Topics Learned

- Fine-tuning LLM with instruction
  - Instruction Fine-tuning
	- Fine-tuning on a single task
	- Multi-task instruction fine-tuning
	- Scaling instruct models
	- Model evaluation techniques
	- Evaluation benchmarks such as GLUE, SuperGLUE, MMLU, etc.
- Parameter efficient fine-tuning
	- What is Parameter efficient fine-tuning (PEFT)
	- PEFT techniques
		- LoRA
		- Soft prompts
